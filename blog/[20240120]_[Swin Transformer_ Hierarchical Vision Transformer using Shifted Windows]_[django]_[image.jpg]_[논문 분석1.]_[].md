## introduction
이 논문 이전까지는 대부분 CNN이 비전 분야 모델링에 활용되었다. 이 논문에서는 NLP에서 사용하던 Transformer를 비전에 활용하는 방법을 제시하였다. Transformer는 시퀀스 모델링 및 변환 작업을 위해 설계된 것으로 데이터내 장거리 의존성을 모델링하기 위해 어텐션 메커니즘을 활용한다.
비전과 언어라는 두 도메인 간의 차이가 있기에 Transformer를 그대로 비전 분야에 적용하기는 어렵다. 2가지 원인이 있다.
#### 1. 스케일(Scale) 문제
첫번째 원인은 스케일 문제이다. NLP에서는 단어 토큰을 고정된 단위로 쪼개서 처리한다. 고정된 단위로 처리해도 텍스트를 처리하는데 있어서는 문제가 없었다. 하지만 비전에서는 객체들의 크기가 다양하므로 고정된 단위로는 처리하기 어렵다.
#### 2. 해상도 문제
이미지의 픽셀 수는 텍스트의 단어보다 훨씬 많기 대문에 고해상도 이미지 처리시 매우 높은 시간복잡도를 갖는다. 

위의 두 문제를 해결하기 위해 계층적 피처 맵을 구성한다. 자세한 내용은 아래에서 확인해보자.

## Method
